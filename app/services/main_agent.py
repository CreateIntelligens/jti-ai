"""
Main Agent - æ ¸å¿ƒå°è©±é‚è¼¯

è·è²¬ï¼š
1. è™•ç†ä¸€èˆ¬å°è©±
2. åˆ¤æ–·ä½¿ç”¨è€…æ„åœ–
3. åœ¨é©ç•¶æ™‚æ©Ÿå‘¼å« MBTI æ¸¬é©—å·¥å…·
4. å•†å“å•ç­”ï¼ˆå¯ç”¨ RAGï¼‰

Agent æ“æœ‰çš„ Toolsï¼š
- start_quiz: é–‹å§‹ MBTI æ¸¬é©—
- get_question: å–å¾—ç•¶å‰é¡Œç›®
- submit_answer: æäº¤ç­”æ¡ˆ
- calculate_persona: è¨ˆç®— MBTI é¡å‹
- recommend_products: æ¨è–¦å•†å“
"""

import os
import logging
from typing import Dict, List, Optional
import google.genai as genai
from google.genai import types
from app.models.session import Session, SessionStep
from app.services.session_manager import session_manager
from app.services.gemini_service import client as gemini_client
from app.tools.tool_executor import tool_executor
from app.services.agent_prompts import (
    MAIN_AGENT_SYSTEM_PROMPT_TEMPLATE,
    CURRENT_QUESTION_TEMPLATE
)
from app.services.conversation_logger import conversation_logger

logger = logging.getLogger(__name__)


class MainAgent:
    """ä¸»è¦å°è©± Agent"""

    def __init__(self):
        self.model_name = os.getenv("GEMINI_MODEL_NAME", "gemini-2.5-flash")

    def _build_system_prompt(self, session: Session) -> str:
        """å»ºç«‹ System Prompt - æ¸¬é©—ç”±å¾Œç«¯è™•ç†ï¼Œé€™è£¡åªçµ¦ LLM åŸºæœ¬è³‡è¨Š"""
        return MAIN_AGENT_SYSTEM_PROMPT_TEMPLATE.format(
            session_id=session.session_id,
            step_value=session.step.value,
            answers_count=len(session.answers),
            persona=session.persona or 'å°šæœªè¨ˆç®—'
        )

    def _build_tools(self) -> List[types.Tool]:
        """å»ºç«‹ tools - åªæœ‰é–‹å§‹æ¸¬é©—èˆ‡æ¨è–¦å•†å“äº¤çµ¦ LLM å‘¼å«"""
        function_declarations = [
            types.FunctionDeclaration(
                name="start_quiz",
                description="é–‹å§‹ MBTI æ¸¬é©—ã€‚ä½¿ç”¨è€…è¡¨é”æƒ³é–‹å§‹æ¸¬é©—æ™‚å‘¼å«ã€‚",
                parameters={
                    "type": "object",
                    "properties": {
                        "session_id": {
                            "type": "string",
                            "description": "Session ID"
                        }
                    },
                    "required": ["session_id"]
                }
            ),
            types.FunctionDeclaration(
                name="recommend_products",
                description="æ ¹æ“š MBTI é¡å‹æ¨è–¦å•†å“ã€‚æ¸¬é©—å®Œæˆå¾Œæˆ–ä½¿ç”¨è€…è¦æ±‚æ¨è–¦æ™‚å‘¼å«ã€‚",
                parameters={
                    "type": "object",
                    "properties": {
                        "session_id": {
                            "type": "string",
                            "description": "Session ID"
                        },
                        "max_results": {
                            "type": "integer",
                            "description": "æœ€å¤šæ¨è–¦å¹¾å€‹å•†å“",
                            "default": 3
                        }
                    },
                    "required": ["session_id"]
                }
            ),
        ]

        # æ•´åˆ Function Declarations + File Search
        return [
            types.Tool(function_declarations=function_declarations),
            types.Tool(
                file_search=types.FileSearch(
                    file_search_store_names=["fileSearchStores/jti-xgvgfp8g1wsq"]
                )
            )
        ]

    async def chat(
        self,
        session_id: str,
        user_message: str,
        store_id: Optional[str] = None
    ) -> Dict:
        """è™•ç†å°è©±"""
        try:
            if not gemini_client:
                return {
                    "error": "Gemini client not initialized",
                    "message": "ç³»çµ±æœªæ­£ç¢ºåˆå§‹åŒ–ï¼Œè«‹æª¢æŸ¥ API Key è¨­å®šã€‚"
                }

            # 1. å–å¾—æˆ–å»ºç«‹ session
            session = session_manager.get_session(session_id)
            if session is None:
                return {
                    "error": "Session not found",
                    "message": "æ‰¾ä¸åˆ°å°è©±è¨˜éŒ„ï¼Œè«‹é‡æ–°é–‹å§‹ã€‚"
                }

            # 2. å»ºç«‹å°è©±å…§å®¹ï¼ˆåŒ…å«æ­·å²å°è©±ä¸²ï¼‰
            system_prompt = self._build_system_prompt(session)
            tools = self._build_tools()

            # 3. å»ºç«‹å®Œæ•´çš„å°è©±ä¸²ï¼ˆåŒ…å«æ­·å²ï¼‰
            conversation_parts = []
            
            # å¦‚æœæœ‰å°è©±æ­·å²ï¼Œå…ˆåŠ å…¥
            if session.chat_history:
                print(f"[DEBUG] è¼‰å…¥å°è©±æ­·å²: {len(session.chat_history)} ç­†")
                logger.info(f"è¼‰å…¥å°è©±æ­·å²: {len(session.chat_history)} ç­†")
                for msg in session.chat_history[-5:]:  # æœ€è¿‘ 5 è¼ªå°è©±
                    role = "user" if msg["role"] == "user" else "model"
                    conversation_parts.append(
                        types.Content(
                            role=role,
                            parts=[types.Part.from_text(text=msg["content"])]
                        )
                    )
                print(f"[DEBUG] conversation_parts åŒ…å« {len(conversation_parts)} æ¢æ­·å²è¨Šæ¯")
                logger.info(f"conversation_parts åŒ…å« {len(conversation_parts)} æ¢æ­·å²è¨Šæ¯")
            else:
                print("[DEBUG] æ²’æœ‰å°è©±æ­·å²ï¼ˆæ–° sessionï¼‰")
                logger.info("æ²’æœ‰å°è©±æ­·å²ï¼ˆæ–° sessionï¼‰")
            
            # åŠ å…¥ç•¶å‰è¨Šæ¯
            # ç³»çµ±æç¤ºç¸½æ˜¯ä»¥å¼·åˆ¶æ€§æŒ‡ä»¤çš„å½¢å¼åŒ…å«
            # ä¸ä½¿ç”¨ [ç³»çµ±æç¤º] æ¨™ç±¤,é¿å… LLM èª¤èªç‚ºæ˜¯åƒè€ƒè³‡è¨Š
            if not conversation_parts:
                # æ–°å°è©±ï¼šç³»çµ±æç¤º + ä½¿ç”¨è€…è¨Šæ¯
                current_user_message = f"{system_prompt}\n\nä½¿ç”¨è€…èªªï¼š{user_message}"
            else:
                # æœ‰æ­·å²ï¼šç›´æ¥é‡ç”³ç³»çµ±æç¤ºï¼ˆä½œç‚ºç•¶å‰å¿…é ˆéµå®ˆçš„è¦å‰‡ï¼‰
                current_user_message = f"{system_prompt}\n\nä½¿ç”¨è€…ç¾åœ¨èªªï¼š{user_message}"

            logger.info(f"[DEBUG] ç™¼é€çµ¦ LLM çš„å®Œæ•´æç¤º:\n{current_user_message[:500]}...")
            
            conversation_parts.append(
                types.Content(
                    role="user",
                    parts=[types.Part.from_text(text=current_user_message)]
                )
            )

            # 4. ç¬¬ä¸€æ¬¡å‘¼å« LLM
            config = types.GenerateContentConfig(tools=tools)
            no_tool_config = types.GenerateContentConfig()
            
            response = gemini_client.models.generate_content(
                model=self.model_name,
                contents=conversation_parts,
                config=config
            )

            # 5. Function calling loop
            tool_calls_log = []
            max_iterations = 5
            iteration = 0

            while iteration < max_iterations:
                # æª¢æŸ¥æ˜¯å¦æœ‰ function call
                has_function_call = False
                
                logger.info(f"Iteration {iteration}: æª¢æŸ¥ LLM å›æ‡‰æ˜¯å¦æœ‰å·¥å…·å‘¼å«")

                if response.candidates and response.candidates[0].content.parts:
                    for part in response.candidates[0].content.parts:
                        if hasattr(part, 'function_call') and part.function_call:
                            has_function_call = True
                            fc = part.function_call
                            tool_name = fc.name
                            tool_args = dict(fc.args) if fc.args else {}

                            # è‡ªå‹•è£œä¸Š session_id
                            if "session_id" in [p for p in tool_args.keys()] or tool_name in [
                                "start_quiz", "get_question", "submit_answer",
                                "calculate_persona", "recommend_products"
                            ]:
                                tool_args["session_id"] = session_id

                            logger.info(f"âœ“ LLM å‘¼å«å·¥å…·: {tool_name}({tool_args})")

                            # åŸ·è¡Œ tool
                            # å¿½ç•¥æ¨¡å‹è…¦è£œçš„ 'query' å·¥å…·ï¼ˆé€™æ˜¯ File Search èª¤ç”¨é€ æˆçš„ï¼‰
                            if tool_name == "query":
                                logger.warning("Ignoring hallucinated tool: query")
                                tool_result = {"error": "è«‹ç›´æ¥å›ç­”å•é¡Œï¼Œä¸è¦ä½¿ç”¨ query å·¥å…·ã€‚"}
                            else:
                                tool_result = await tool_executor.execute(tool_name, tool_args)

                            tool_calls_log.append({
                                "tool": tool_name,
                                "args": tool_args,
                                "result": tool_result
                            })

                            # åŠ å…¥å°è©±æ­·å²
                            conversation_parts.append(
                                types.Content(
                                    role="model",
                                    parts=[part]
                                )
                            )
                            conversation_parts.append(
                                types.Content(
                                    role="user",
                                    parts=[types.Part.from_function_response(
                                        name=tool_name,
                                        response={"result": tool_result}
                                    )]
                                )
                            )

                            # é‡æ–°å–å¾—æœ€æ–°çš„ session ç‹€æ…‹ä»¥æ›´æ–°ç³»çµ±æç¤º
                            updated_session = session_manager.get_session(session_id)
                            updated_system_prompt = self._build_system_prompt(updated_session)
                            logger.info(f"[DEBUG] æ›´æ–°ç³»çµ±æç¤º")
                            logger.info(f"  - current_q_index: {updated_session.current_q_index}")
                            logger.info(f"  - answers: {updated_session.answers}")
                            logger.info(f"  - current_question_id: {updated_session.current_question.get('id') if updated_session.current_question else None}")
                            logger.info(f"  - system_prompt åŒ…å«ç•¶å‰é¡Œç›®: {'ğŸ¯ ç•¶å‰é¡Œç›®' in updated_system_prompt}")
                            logger.info(f"  - system_prompt é•·åº¦: {len(updated_system_prompt)} å­—å…ƒ")
                            if updated_session.current_question:
                                logger.info(f"  - å®Œæ•´ç³»çµ±æç¤º:\n{updated_system_prompt}")

                            # ç¹¼çºŒå°è©± - æ ¹æ“šå·¥å…·è¿”å›å…§å®¹æ±ºå®šå¦‚ä½•æ›´æ–°ç³»çµ±æç¤º
                            if "instruction_for_llm" in tool_result:
                                # æœ‰æ˜ç¢ºæŒ‡ç¤ºï¼Œç›´æ¥ä½¿ç”¨
                                instruction = tool_result['instruction_for_llm']
                            elif "message" in tool_result:
                                # æœ‰é è¨­è¨Šæ¯ï¼Œè«‹ LLM ç”¨è‡ªç„¶èªæ°£å›è¦†ä¸¦å®Œæ•´ä¿ç•™å…§å®¹
                                if tool_name == "start_quiz":
                                    instruction = (
                                        "è«‹ç”¨è‡ªç„¶èªæ°£å›æ‡‰ï¼Œä¸¦åœ¨å›è¦†ä¸­å®Œæ•´ä¿ç•™é¡Œç›®èˆ‡é¸é …æ–‡å­—ï¼ˆåŸå°ä¸å‹•ï¼‰ã€‚"
                                        "å¯åœ¨å‰å¾ŒåŠ ä¸€å¥å‹å–„çš„å¼•å°è©±ï¼š\n"
                                        f"{tool_result['message']}"
                                    )
                                else:
                                    instruction = (
                                        "è«‹ç”¨è‡ªç„¶èªæ°£å›æ‡‰ï¼Œä¸¦åœ¨å›è¦†ä¸­å®Œæ•´ä¿ç•™ä»¥ä¸‹å…§å®¹ã€‚"
                                        "å¯åœ¨å‰å¾ŒåŠ ä¸€å¥å‹å–„çš„å¼•å°è©±ï¼š\n"
                                        f"{tool_result['message']}"
                                    )
                            else:
                                # æ²’æœ‰æ˜ç¢ºæŒ‡ç¤ºï¼Œè®“ LLM è‡ªç”±ç™¼æ®
                                instruction = "è«‹æ ¹æ“šå·¥å…·åŸ·è¡Œçµæœè‡ªç„¶å›æ‡‰ä½¿ç”¨è€…ã€‚"

                            conversation_parts.append(
                                types.Content(
                                    role="user",
                                    parts=[types.Part.from_text(text=f"{updated_system_prompt}\n\n{instruction}")]
                                )
                            )

                            response = gemini_client.models.generate_content(
                                model=self.model_name,
                                contents=conversation_parts,
                                config=no_tool_config
                            )
                            break

                if not has_function_call:
                    break

                iteration += 1

            # 5. å–å¾—æœ€çµ‚å›æ‡‰ï¼ˆå„ªå…ˆ LLM ç”¢ç”Ÿçš„æ–‡æœ¬ï¼‰
            final_message = ""

            if response.candidates and response.candidates[0].content.parts:
                for part in response.candidates[0].content.parts:
                    if hasattr(part, 'text') and part.text:
                        final_message += part.text

            if not final_message and tool_calls_log:
                # å¾Œå‚™ï¼šè‹¥ LLM æ²’æœ‰ç”¢ç”Ÿæ–‡å­—ï¼Œæ‰ä½¿ç”¨å·¥å…· message
                last_tool_call = tool_calls_log[-1]
                tool_result = last_tool_call.get("result", {})
                if isinstance(tool_result, dict) and "message" in tool_result:
                    final_message = tool_result["message"]
                    logger.warning(f"LLM ç„¡æ–‡å­—å›æ‡‰ï¼Œæ”¹ç”¨å·¥å…· message: tool={last_tool_call.get('tool')}")

            if not final_message:
                final_message = "AIç›®å‰æ•…éšœ è«‹è¯çµ¡"
                logger.warning(f"LLM æœªç”Ÿæˆä»»ä½•æ–‡æœ¬å›æ‡‰ï¼Œä½¿ç”¨è€…è¼¸å…¥ï¼š{user_message[:50]}")

            # 6. ä¿å­˜å°è©±æ­·å²
            updated_session = session_manager.get_session(session_id)
            session_manager.add_chat_message(session_id, "user", user_message)
            session_manager.add_chat_message(session_id, "assistant", final_message)

            # 7. è¨˜éŒ„å°è©±æ—¥èªŒï¼ˆç”¨æ–¼ debugï¼‰
            conversation_logger.log_conversation(
                session_id=session_id,
                user_message=user_message,
                agent_response=final_message,
                tool_calls=tool_calls_log,
                session_state={
                    "step": updated_session.step.value if updated_session else None,
                    "answers_count": len(updated_session.answers) if updated_session else 0,
                    "persona": updated_session.persona if updated_session else None,
                    "current_question_id": updated_session.current_question.get("id") if updated_session and updated_session.current_question else None
                } if updated_session else None
            )

            # 8. å›å‚³çµæœ
            return {
                "message": final_message,
                "session": updated_session.model_dump() if updated_session else None,
                "tool_calls": tool_calls_log
            }

        except Exception as e:
            logger.error(f"Chat failed: {e}", exc_info=True)
            
            # è¨˜éŒ„éŒ¯èª¤åˆ°å°è©±æ—¥èªŒ
            conversation_logger.log_conversation(
                session_id=session_id,
                user_message=user_message,
                agent_response=f"[ERROR] {str(e)}",
                error=str(e)
            )
            
            return {
                "error": str(e),
                "message": f"æŠ±æ­‰ï¼Œç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"
            }

    async def chat_with_tool_result(
        self,
        session_id: str,
        user_message: str,
        tool_name: str,
        tool_args: dict,
        tool_result: dict
    ) -> dict:
        """
        ç•¶å¾Œç«¯å·²åŸ·è¡Œå·¥å…·æ™‚ï¼Œè®“ LLM æ ¹æ“šå·¥å…·çµæœç”Ÿæˆå›æ‡‰

        ç”¨æ–¼ QUIZ æµç¨‹ï¼šå¾Œç«¯åˆ¤æ–·ä¸¦å‘¼å«å·¥å…·ï¼ŒLLM è² è²¬ç”Ÿæˆè‡ªç„¶å›æ‡‰
        """
        try:
            session = session_manager.get_session(session_id)
            if not session:
                return {"error": "Session not found", "message": "æ‰¾ä¸åˆ° session"}

            # å»ºç«‹å°è©±ä¸Šä¸‹æ–‡
            conversation_parts = []

            # åŠ å…¥æ­·å²å°è©±ï¼ˆæœ€å¤š 5 ç­†ï¼‰
            if session.chat_history:
                recent_history = session.chat_history[-5:]
                for msg in recent_history:
                    # è½‰æ› roleï¼šassistant â†’ model
                    role = "model" if msg["role"] == "assistant" else msg["role"]
                    conversation_parts.append(
                        types.Content(
                            role=role,
                            parts=[types.Part.from_text(text=msg["content"])]
                        )
                    )

            # æ ¹æ“šå·¥å…·çµæœç”ŸæˆæŒ‡ç¤º
            if "instruction_for_llm" in tool_result:
                instruction = tool_result["instruction_for_llm"]
            elif tool_name == "start_quiz" and tool_result.get("current_question"):
                # é–‹å§‹æ¸¬é©—ï¼Œé¡¯ç¤ºç¬¬ä¸€é¡Œ
                q = tool_result["current_question"]
                instruction = f"""æ¸¬é©—å·²é–‹å§‹ï¼Œè«‹ç”¨å‹å–„çš„èªæ°£ä»‹ç´¹ä¸¦å•ç¬¬ä¸€é¡Œã€‚

ç¬¬1é¡Œï¼š{q['text']}
A. {q['options'][0]['text']}
B. {q['options'][1]['text']}

å¿…é ˆå®Œæ•´é¡¯ç¤ºé¡Œç›®å’Œé¸é …ï¼Œå¯ä»¥åŠ ä¸€å¥ç°¡çŸ­çš„é–‹å ´ç™½ã€‚"""
            elif "recommend_result" in tool_result:
                # æ¸¬é©—å®Œæˆ + æ¨è–¦
                persona_id = tool_result.get('persona_result', {}).get('persona_id', 'Unknown')
                recommend_msg = tool_result['recommend_result'].get('message', '')
                instruction = f"""ä½¿ç”¨è€…å‰›å®Œæˆ MBTI æ¸¬é©—ï¼Œé¡å‹æ˜¯ {persona_id}ã€‚

{recommend_msg}

è«‹ç”¨å‹å–„ã€é¼“å‹µçš„èªæ°£å›æ‡‰ï¼ŒåŒ…å«ï¼š
1. æ­å–œå®Œæˆæ¸¬é©—
2. MBTI é¡å‹åŠç‰¹è³ªæè¿°
3. æ¨è–¦çš„å•†å“"""
            else:
                instruction = "è«‹ç°¡çŸ­å›æ‡‰ä½¿ç”¨è€…"

            # çµ„åˆï¼šsystem prompt + ä½¿ç”¨è€…è¨Šæ¯ + æŒ‡ç¤º
            system_prompt = self._build_system_prompt(session)
            full_prompt = f"""{system_prompt}

ä½¿ç”¨è€…èªªï¼š{user_message}

{instruction}"""

            conversation_parts.append(
                types.Content(
                    role="user",
                    parts=[types.Part.from_text(text=full_prompt)]
                )
            )

            # å‘¼å« LLM ç”Ÿæˆå›æ‡‰
            response = gemini_client.models.generate_content(
                model=self.model_name,
                contents=conversation_parts
            )

            # æå–å›æ‡‰
            final_message = ""
            if response.candidates and response.candidates[0].content.parts:
                for part in response.candidates[0].content.parts:
                    if hasattr(part, 'text') and part.text:
                        final_message += part.text

            if not final_message:
                final_message = "æ”¶åˆ°ï¼"

            # è¨˜éŒ„å°è©±ï¼ˆä¸åœ¨é€™è£¡è¨˜éŒ„ï¼Œç”± API å±¤è¨˜éŒ„ï¼‰
            # session_manager.add_chat_message(session_id, "user", user_message)
            # session_manager.add_chat_message(session_id, "assistant", final_message)

            return {
                "message": final_message,
                "session": session.model_dump()
            }

        except Exception as e:
            logger.error(f"chat_with_tool_result failed: {e}", exc_info=True)
            return {
                "error": str(e),
                "message": "æ”¶åˆ°ï¼"
            }


# å…¨åŸŸå¯¦ä¾‹
main_agent = MainAgent()
